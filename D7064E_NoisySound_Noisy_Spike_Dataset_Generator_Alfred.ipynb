{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Welcome! This script should generate a brand new spike dataset (numpy arrays) from the .wav home sound dataset. This is to save on memory and time, as we won't have to preprocess the dataset multiple times. Trust me, this script takes a loooooong time to run.\n",
        "\n",
        "You don't have to run this script, as the dataset is saved to my google drive and I will have zipped it up and shared it with you all.\n",
        "\n",
        "I took some help from AI to write this code."
      ],
      "metadata": {
        "id": "MMVD1a-IeKB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Update: adding noise\n",
        "I've added functionality for adding white gaussian noise within a random SNR (Signal-to-Noise Ratio) to each sample. Feel free to use this code to generate a dataset with any desired amount of white gaussian noise.\n",
        "\n",
        "Using SNR means the noise will be proportional to the signal (original audio). Note that:\n",
        "\n",
        "SNR = 0: noise and signal have equal dB.\n",
        "\n",
        "SNR < 0: noise is *louder* than signal, dB of noise is higher.\n",
        "\n",
        "SNR > 0: noise is *quieter* than signal, dB of noise is lower."
      ],
      "metadata": {
        "id": "t2K-nj3f_MSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run once, also runtime may ask to be restarted, that's fine\n",
        "!pip install rockpool\n",
        "!pip install \"numpy<2\" \"jax==0.4.20\" \"jaxlib==0.4.20\"\n",
        "!pip install samna\n",
        "!pip install bitstruct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WWsl5iZSgcG_",
        "outputId": "57935849-7a6c-445f-a95d-bc20023e879f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rockpool in /usr/local/lib/python3.12/dist-packages (3.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rockpool) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from rockpool) (1.16.3)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: jax==0.4.20 in /usr/local/lib/python3.12/dist-packages (0.4.20)\n",
            "Requirement already satisfied: jaxlib==0.4.20 in /usr/local/lib/python3.12/dist-packages (0.4.20)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from jax==0.4.20) (0.5.4)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.12/dist-packages (from jax==0.4.20) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.12/dist-packages (from jax==0.4.20) (1.16.3)\n",
            "Collecting samna\n",
            "  Using cached samna-0.48.2-py3-none-any.whl.metadata (375 bytes)\n",
            "Using cached samna-0.48.2-py3-none-any.whl (6.8 kB)\n",
            "Installing collected packages: samna\n",
            "Successfully installed samna-0.48.2\n",
            "Collecting bitstruct\n",
            "  Downloading bitstruct-8.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Downloading bitstruct-8.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.7/83.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitstruct\n",
            "Successfully installed bitstruct-8.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "zip_file_path = '/content/drive/MyDrive/D7046E_SNN_project_dataset/building_106_kitchen.zip'\n",
        "extract_path = '/content/dataset'\n",
        "\n",
        "with ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNsdDlRAhJsp",
        "outputId": "4a200a64-b90f-4eb3-b7f7-0e5d3bc6b424"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_root_dir = '/content/dataset/building_106_kitchen/training_segments'\n",
        "output_dir = '/content/drive/MyDrive/D7046E_SNN_project_dataset/kitchen_spike_dataset_noisy'"
      ],
      "metadata": {
        "id": "BHz-bv7Hw61u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QqN5KtUed1oH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from IPython.display import Image, Audio, display\n",
        "import numpy as np\n",
        "import librosa\n",
        "from rockpool.devices.xylo.syns61201 import AFESim\n",
        "from rockpool.timeseries import TSContinuous\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import gc\n",
        "\n",
        "\n",
        "# add white noise to audio at a given SNR [dB] (Signal to Noise Ratio)\n",
        "def add_white_noise(audio, snr_db):\n",
        "    signal_power = np.mean(audio ** 2)\n",
        "    snr_linear = 10 ** (snr_db / 10)\n",
        "    noise_power = signal_power / snr_linear\n",
        "\n",
        "    # from a normal distribution = gaussian noise\n",
        "    noise = np.random.normal(0, np.sqrt(noise_power), audio.shape)\n",
        "    return audio + noise\n",
        "\n",
        "\n",
        "def convert_audio_to_spikes(\n",
        "    audio_path,\n",
        "    sample_T,\n",
        "    raster_period,\n",
        "    add_noise=False,\n",
        "    snr_range=(0, 20)  # dB\n",
        "):\n",
        "    afe = AFESim(\n",
        "        fs=110e3,\n",
        "        raster_period=raster_period,\n",
        "        max_spike_per_raster_period=15,\n",
        "        add_noise=False,      # keep AFE clean\n",
        "        add_offset=False,\n",
        "        add_mismatch=False,\n",
        "        seed=None,\n",
        "    ).timed()\n",
        "\n",
        "    audio, sr = librosa.load(audio_path, sr=None, mono=True)\n",
        "\n",
        "    # add noise here\n",
        "    if add_noise:\n",
        "        snr_db = np.random.uniform(*snr_range)\n",
        "        audio = add_white_noise(audio, snr_db)\n",
        "\n",
        "    times = np.arange(len(audio)) / sr\n",
        "    ts_audio = TSContinuous(times, audio[:, None])\n",
        "\n",
        "    # we have a bunch of garbage collection like this to save memory\n",
        "    del audio, times\n",
        "\n",
        "    # convert audio to spikes\n",
        "    spikes, _, _ = afe(ts_audio)\n",
        "\n",
        "    del ts_audio, afe\n",
        "\n",
        "    # convert to raster format (time_steps x channels)\n",
        "    spike_raster = spikes.raster(dt=raster_period, add_events=True)\n",
        "    del spikes\n",
        "\n",
        "    # validate we got spikes\n",
        "    if spike_raster.shape[0] == 0:\n",
        "        # if no spikes generated, create empty raster\n",
        "        spike_raster = np.zeros((sample_T, 16), dtype=np.float32)\n",
        "        return spike_raster\n",
        "\n",
        "    # pad or truncate to sample_T time steps\n",
        "    # (300 10ms time steps = 3 seconds)\n",
        "    if spike_raster.shape[0] < sample_T:\n",
        "        padding = np.zeros((sample_T - spike_raster.shape[0], spike_raster.shape[1]), dtype=np.float32)\n",
        "        spike_raster = np.vstack([spike_raster, padding])\n",
        "        del padding\n",
        "    else:\n",
        "        spike_raster = spike_raster[:sample_T, :]\n",
        "\n",
        "    spike_raster = spike_raster.astype(np.float32)\n",
        "    return spike_raster\n",
        "\n",
        "\n",
        "def preprocess_batch(\n",
        "    audio_root_dir,\n",
        "    output_dir,\n",
        "    sample_T,\n",
        "    raster_period,\n",
        "    batch_start=0,\n",
        "    batch_size=4,\n",
        "    snr_range=(0, 20),\n",
        "    add_noise=False\n",
        "):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Get all classes\n",
        "    all_classes = sorted([d for d in os.listdir(audio_root_dir)\n",
        "                         if os.path.isdir(os.path.join(audio_root_dir, d))])\n",
        "\n",
        "    # Select batch of classes to process\n",
        "    classes_to_process = all_classes[batch_start:batch_start + batch_size]\n",
        "\n",
        "    if not classes_to_process:\n",
        "        print(f\"No classes to process at batch_start={batch_start}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Processing batch: classes {batch_start} to {batch_start + len(classes_to_process) - 1}\")\n",
        "    print(f\"Classes in this batch: {classes_to_process}\")\n",
        "\n",
        "    # Create/load metadata\n",
        "    metadata_path = os.path.join(output_dir, 'metadata.json')\n",
        "    if os.path.exists(metadata_path):\n",
        "        with open(metadata_path, 'r') as f:\n",
        "            metadata = json.load(f)\n",
        "        class_to_idx = metadata['class_to_idx']\n",
        "    else:\n",
        "        # first batch - create metadata\n",
        "        class_to_idx = {cls: i for i, cls in enumerate(all_classes)}\n",
        "        metadata = {\n",
        "            'classes': all_classes,\n",
        "            'class_to_idx': class_to_idx,\n",
        "            'sample_T': sample_T,\n",
        "            'raster_period': raster_period,\n",
        "            'num_channels': 16,\n",
        "        }\n",
        "        with open(metadata_path, 'w') as f:\n",
        "            json.dump(metadata, f, indent=2)\n",
        "        print(f\"Created metadata for all {len(all_classes)} classes\")\n",
        "\n",
        "    # load existing sample info if it exists\n",
        "    sample_info_path = os.path.join(output_dir, 'sample_info.npy')\n",
        "    if os.path.exists(sample_info_path):\n",
        "        sample_info = np.load(sample_info_path, allow_pickle=True).tolist()\n",
        "    else:\n",
        "        sample_info = []\n",
        "\n",
        "    # Process each class in this batch\n",
        "    total_processed = 0\n",
        "    total_errors = 0\n",
        "    error_log = []\n",
        "\n",
        "    for class_name in classes_to_process:\n",
        "        class_path = os.path.join(audio_root_dir, class_name)\n",
        "        class_idx = class_to_idx[class_name]\n",
        "\n",
        "        # Create output directory for this class\n",
        "        class_output_dir = os.path.join(output_dir, class_name)\n",
        "        os.makedirs(class_output_dir, exist_ok=True)\n",
        "\n",
        "        # Get all WAV files\n",
        "        wav_files = [f for f in os.listdir(class_path) if f.endswith('.wav')]\n",
        "\n",
        "        print(f\"\\nProcessing '{class_name}' ({len(wav_files)} samples)...\")\n",
        "\n",
        "        class_errors = 0\n",
        "        for idx, wav_file in enumerate(tqdm(wav_files, desc=f\"  {class_name}\")):\n",
        "            audio_path = os.path.join(class_path, wav_file)\n",
        "            output_filename = wav_file.replace('.wav', '.npy')\n",
        "            output_path = os.path.join(class_output_dir, output_filename)\n",
        "\n",
        "            # Skip if already processed\n",
        "            if os.path.exists(output_path):\n",
        "                continue\n",
        "\n",
        "            spike_raster = convert_audio_to_spikes(\n",
        "                audio_path,\n",
        "                sample_T,\n",
        "                raster_period,\n",
        "                add_noise,\n",
        "                snr_range # CHOOSE SNR [dB] HERE\n",
        "            )\n",
        "\n",
        "            np.save(output_path, spike_raster)\n",
        "            sample_info.append((output_path, class_idx))\n",
        "            total_processed += 1\n",
        "            del spike_raster\n",
        "\n",
        "            if idx % 5 == 0:\n",
        "                gc.collect()\n",
        "\n",
        "\n",
        "        # Save sample info after each class\n",
        "        np.save(sample_info_path, sample_info, allow_pickle=True)\n",
        "        gc.collect()\n",
        "\n",
        "\n",
        "    return len(all_classes), batch_start + batch_size"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear memory\n",
        "gc.collect()\n",
        "\n",
        "# AFESim parameters (not creating it here - created fresh for each file)\n",
        "sample_T = 300\n",
        "raster_period = 10e-3\n",
        "\n",
        "# CHOOSE SNR HERE\n",
        "snr_range = (0,15)\n",
        "add_noise = True\n",
        "\n",
        "# PROCESS IN BATCHES (of classes)\n",
        "batch_start = 23  # start at class\n",
        "\n",
        "batch_size = 1  # process n classes at a time\n",
        "\n",
        "print(f\"\\nConfiguration:\")\n",
        "print(f\"  Batch start: {batch_start}\")\n",
        "print(f\"  Batch size: {batch_size}\")\n",
        "\n",
        "total_classes, next_batch = preprocess_batch(\n",
        "    audio_root_dir=audio_root_dir,\n",
        "    output_dir=output_dir,\n",
        "    sample_T=sample_T,\n",
        "    raster_period=raster_period,\n",
        "    batch_start=batch_start,\n",
        "    batch_size=batch_size,\n",
        "    snr_range=snr_range,\n",
        "    add_noise=add_noise\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kxim2gzn9SxZ",
        "outputId": "0751b52d-2b98-4788-fb47-4e01c3ec13e7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Configuration:\n",
            "  Batch start: 23\n",
            "  Batch size: 1\n",
            "Processing batch: classes 23 to 23\n",
            "Classes in this batch: ['water_tap']\n",
            "\n",
            "Processing 'water_tap' (115 samples)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  water_tap: 100%|██████████| 115/115 [07:00<00:00,  3.66s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Becuase TimedModuleWrapper was giving me trouble I tried switching to non-timed simulation.\n",
        "\n",
        "First 4 classes have 10 ms raster period, max 15 spikes: 88.9% empty\\\n",
        "First 4 classes have 20 ms raster period, max 100 spikes: 91.7% empty\\\n",
        "First 4 classes have 50 ms raster period, max 100 spikes: 91.7% empty\\\n",
        "First 4 classes have 5 ms raster period, max 100 spikes: 91.7% empty\n",
        "\n",
        "conclusion: adjusting these parameters doesn't help make more spikes\n",
        "\n",
        "Tried scaling voltage of input to expected RMS:\\\n",
        "First 4 classes have 10 ms raster period, max 15 spikes: 11.1% empty (didn't end up using this anyway, while fewer samples are empty, most are still super sparse, this is still worth considering though)\n",
        "\n",
        "In the end, I switched back to TimedModuleWrapper (.timed()) and created a new afesim for every single audio sample, making sure to delete each simulation and variables after I've used them to save on memory. This is very slow but seems to work fine.\n"
      ],
      "metadata": {
        "id": "LSSjlL2rvMcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for testing different noise\n",
        "# path to each training class\n",
        "train_segments_path = '/content/dataset/building_106_kitchen/training_segments'\n",
        "class_directories = []\n",
        "for item in os.listdir(train_segments_path):\n",
        "    item_path = os.path.join(train_segments_path, item)\n",
        "    if os.path.isdir(item_path):\n",
        "        class_directories.append(item)\n",
        "\n",
        "# one random audio sample from each class\n",
        "# run this cell again to get different samples\n",
        "for class_name in class_directories:\n",
        "    class_path = os.path.join(train_segments_path, class_name)\n",
        "    wav_files = [f for f in os.listdir(class_path) if f.endswith('.wav')]\n",
        "    if wav_files:\n",
        "        random_wav_file = random.choice(wav_files)\n",
        "        random_wav_file_path = os.path.join(class_path, random_wav_file)\n",
        "        print(f\"\\nClass: {class_name}\")\n",
        "        audio_data, sr = librosa.load(random_wav_file_path, sr=None, mono=True)\n",
        "        noisy_audio_data = add_white_noise(audio_data, snr_db=15)\n",
        "        display(Audio(data=noisy_audio_data, rate=sr))\n"
      ],
      "metadata": {
        "id": "JRyxTfE48YyS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}