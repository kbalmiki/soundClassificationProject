{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Welcome! This script should generate a brand new spike dataset (numpy arrays) from the .wav home sound dataset. This is to save on memory and time, as we won't have to preprocess the dataset multiple times. Trust me, this script takes a loooooong time to run.\n",
        "\n",
        "You don't have to run this script, as the dataset is saved to my google drive and I will have zipped it up and shared it with you all.\n",
        "\n",
        "I took some help from AI to write this code."
      ],
      "metadata": {
        "id": "MMVD1a-IeKB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run once, also runtime may ask to be restarted, that's fine\n",
        "!pip install rockpool\n",
        "!pip install \"numpy<2\" \"jax==0.4.20\" \"jaxlib==0.4.20\"\n",
        "!pip install samna\n",
        "!pip install bitstruct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WWsl5iZSgcG_",
        "outputId": "6f469f0f-de75-43d8-e561-a3c4e40164d0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rockpool in /usr/local/lib/python3.12/dist-packages (3.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rockpool) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from rockpool) (1.16.3)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: jax==0.4.20 in /usr/local/lib/python3.12/dist-packages (0.4.20)\n",
            "Requirement already satisfied: jaxlib==0.4.20 in /usr/local/lib/python3.12/dist-packages (0.4.20)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from jax==0.4.20) (0.5.4)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.12/dist-packages (from jax==0.4.20) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.12/dist-packages (from jax==0.4.20) (1.16.3)\n",
            "Requirement already satisfied: samna in /usr/local/lib/python3.12/dist-packages (0.48.2)\n",
            "Requirement already satisfied: bitstruct in /usr/local/lib/python3.12/dist-packages (8.21.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "zip_file_path = '/content/drive/MyDrive/D7046E_SNN_project_dataset/building_106_kitchen.zip'\n",
        "extract_path = '/content/dataset'\n",
        "\n",
        "with ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "audio_root_dir = '/content/dataset/building_106_kitchen/training_segments'\n",
        "output_dir = '/content/drive/MyDrive/D7046E_SNN_project_dataset/kitchen_spike_dataset'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNsdDlRAhJsp",
        "outputId": "c2ec87f0-2abf-414b-a135-51e243149783"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqN5KtUed1oH",
        "outputId": "ae0682f3-d25c-4803-a4e7-039955f89250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Configuration:\n",
            "  Batch start: 23\n",
            "  Batch size: 1\n",
            "Processing batch: classes 23 to 23\n",
            "Classes in this batch: ['water_tap']\n",
            "\n",
            "Processing 'water_tap' (115 samples)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  water_tap: 100%|██████████| 115/115 [06:18<00:00,  3.29s/it]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "from rockpool.devices.xylo.syns61201 import AFESim\n",
        "from rockpool.timeseries import TSContinuous\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import gc\n",
        "\n",
        "\n",
        "def convert_audio_to_spikes(audio_path, sample_T, raster_period):\n",
        "\n",
        "    # create a new AFESim for each file\n",
        "    afe = AFESim(\n",
        "        fs=110e3,\n",
        "        raster_period=raster_period,\n",
        "        max_spike_per_raster_period=15,\n",
        "        add_noise=False,\n",
        "        add_offset=False,\n",
        "        add_mismatch=False,\n",
        "        seed=None,\n",
        "    ).timed()\n",
        "\n",
        "    audio, sr = librosa.load(audio_path, sr=None, mono=True)\n",
        "\n",
        "    times = np.arange(len(audio)) / sr\n",
        "    ts_audio = TSContinuous(times, audio[:, None])\n",
        "\n",
        "    # we have a bunch of garbage collection like this to save memory\n",
        "    del audio, times\n",
        "\n",
        "    # convert audio to spikes\n",
        "    spikes, _, _ = afe(ts_audio)\n",
        "\n",
        "    del ts_audio, afe\n",
        "\n",
        "    # convert to raster format (time_steps x channels)\n",
        "    spike_raster = spikes.raster(dt=raster_period, add_events=True)\n",
        "    del spikes\n",
        "\n",
        "    # validate we got spikes\n",
        "    if spike_raster.shape[0] == 0:\n",
        "        # if no spikes generated, create empty raster\n",
        "        spike_raster = np.zeros((sample_T, 16), dtype=np.float32)\n",
        "        return spike_raster\n",
        "\n",
        "    # pad or truncate to sample_T time steps\n",
        "    # (300 10ms time steps = 3 seconds)\n",
        "    if spike_raster.shape[0] < sample_T:\n",
        "        padding = np.zeros((sample_T - spike_raster.shape[0], spike_raster.shape[1]), dtype=np.float32)\n",
        "        spike_raster = np.vstack([spike_raster, padding])\n",
        "        del padding\n",
        "    else:\n",
        "        spike_raster = spike_raster[:sample_T, :]\n",
        "\n",
        "    spike_raster = spike_raster.astype(np.float32)\n",
        "    return spike_raster\n",
        "\n",
        "\n",
        "def preprocess_batch(\n",
        "    audio_root_dir,\n",
        "    output_dir,\n",
        "    sample_T,\n",
        "    raster_period,\n",
        "    batch_start=0,\n",
        "    batch_size=4\n",
        "):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Get all classes\n",
        "    all_classes = sorted([d for d in os.listdir(audio_root_dir)\n",
        "                         if os.path.isdir(os.path.join(audio_root_dir, d))])\n",
        "\n",
        "    # Select batch of classes to process\n",
        "    classes_to_process = all_classes[batch_start:batch_start + batch_size]\n",
        "\n",
        "    if not classes_to_process:\n",
        "        print(f\"No classes to process at batch_start={batch_start}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Processing batch: classes {batch_start} to {batch_start + len(classes_to_process) - 1}\")\n",
        "    print(f\"Classes in this batch: {classes_to_process}\")\n",
        "\n",
        "    # Create/load metadata\n",
        "    metadata_path = os.path.join(output_dir, 'metadata.json')\n",
        "    if os.path.exists(metadata_path):\n",
        "        with open(metadata_path, 'r') as f:\n",
        "            metadata = json.load(f)\n",
        "        class_to_idx = metadata['class_to_idx']\n",
        "    else:\n",
        "        # first batch - create metadata\n",
        "        class_to_idx = {cls: i for i, cls in enumerate(all_classes)}\n",
        "        metadata = {\n",
        "            'classes': all_classes,\n",
        "            'class_to_idx': class_to_idx,\n",
        "            'sample_T': sample_T,\n",
        "            'raster_period': raster_period,\n",
        "            'num_channels': 16,\n",
        "        }\n",
        "        with open(metadata_path, 'w') as f:\n",
        "            json.dump(metadata, f, indent=2)\n",
        "        print(f\"Created metadata for all {len(all_classes)} classes\")\n",
        "\n",
        "    # load existing sample info if it exists\n",
        "    sample_info_path = os.path.join(output_dir, 'sample_info.npy')\n",
        "    if os.path.exists(sample_info_path):\n",
        "        sample_info = np.load(sample_info_path, allow_pickle=True).tolist()\n",
        "    else:\n",
        "        sample_info = []\n",
        "\n",
        "    # Process each class in this batch\n",
        "    total_processed = 0\n",
        "    total_errors = 0\n",
        "    error_log = []\n",
        "\n",
        "    for class_name in classes_to_process:\n",
        "        class_path = os.path.join(audio_root_dir, class_name)\n",
        "        class_idx = class_to_idx[class_name]\n",
        "\n",
        "        # Create output directory for this class\n",
        "        class_output_dir = os.path.join(output_dir, class_name)\n",
        "        os.makedirs(class_output_dir, exist_ok=True)\n",
        "\n",
        "        # Get all WAV files\n",
        "        wav_files = [f for f in os.listdir(class_path) if f.endswith('.wav')]\n",
        "\n",
        "        print(f\"\\nProcessing '{class_name}' ({len(wav_files)} samples)...\")\n",
        "\n",
        "        class_errors = 0\n",
        "        for idx, wav_file in enumerate(tqdm(wav_files, desc=f\"  {class_name}\")):\n",
        "            audio_path = os.path.join(class_path, wav_file)\n",
        "            output_filename = wav_file.replace('.wav', '.npy')\n",
        "            output_path = os.path.join(class_output_dir, output_filename)\n",
        "\n",
        "            # Skip if already processed\n",
        "            if os.path.exists(output_path):\n",
        "                continue\n",
        "\n",
        "            spike_raster = convert_audio_to_spikes(\n",
        "                audio_path, sample_T, raster_period\n",
        "            )\n",
        "            np.save(output_path, spike_raster)\n",
        "            sample_info.append((output_path, class_idx))\n",
        "            total_processed += 1\n",
        "            del spike_raster\n",
        "\n",
        "            if idx % 5 == 0:\n",
        "                gc.collect()\n",
        "\n",
        "\n",
        "        # Save sample info after each class\n",
        "        np.save(sample_info_path, sample_info, allow_pickle=True)\n",
        "        gc.collect()\n",
        "\n",
        "\n",
        "    return len(all_classes), batch_start + batch_size\n",
        "\n",
        "\n",
        "\n",
        "# Clear memory\n",
        "gc.collect()\n",
        "\n",
        "# AFESim parameters (not creating it here - created fresh for each file)\n",
        "sample_T = 300\n",
        "raster_period = 10e-3\n",
        "\n",
        "# PROCESS IN BATCHES (of classes)\n",
        "batch_start = 23  # start at class\n",
        "\n",
        "batch_size = 1  # process n classes at a time\n",
        "\n",
        "print(f\"\\nConfiguration:\")\n",
        "print(f\"  Batch start: {batch_start}\")\n",
        "print(f\"  Batch size: {batch_size}\")\n",
        "\n",
        "total_classes, next_batch = preprocess_batch(\n",
        "    audio_root_dir=audio_root_dir,\n",
        "    output_dir=output_dir,\n",
        "    sample_T=sample_T,\n",
        "    raster_period=raster_period,\n",
        "    batch_start=batch_start,\n",
        "    batch_size=batch_size\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Becuase TimedModuleWrapper was giving me trouble I tried switching to non-timed simulation.\n",
        "\n",
        "First 4 classes have 10 ms raster period, max 15 spikes: 88.9% empty\\\n",
        "First 4 classes have 20 ms raster period, max 100 spikes: 91.7% empty\\\n",
        "First 4 classes have 50 ms raster period, max 100 spikes: 91.7% empty\\\n",
        "First 4 classes have 5 ms raster period, max 100 spikes: 91.7% empty\n",
        "\n",
        "conclusion: adjusting these parameters doesn't help make more spikes\n",
        "\n",
        "Tried scaling voltage of input to expected RMS:\\\n",
        "First 4 classes have 10 ms raster period, max 15 spikes: 11.1% empty (didn't end up using this anyway, while fewer samples are empty, most are still super sparse, this is still worth considering though)\n",
        "\n",
        "In the end, I switched back to TimedModuleWrapper (.timed()) and created a new afesim for every single audio sample, making sure to delete each simulation and variables after I've used them to save on memory. This is very slow but seems to work fine.\n"
      ],
      "metadata": {
        "id": "LSSjlL2rvMcv"
      }
    }
  ]
}